---
title: 第四章、传输层
date: 2023-01-11 19:59:48
img: /medias/images/计算机网络.png
tags: [计算机网络]
categories: 笔记
---

# 第四章、传输层

## 4.1 transport-layer services

### 在不同主机上运行的应用进程之间提供逻辑通信（logical communication）

### 在终端系统中运行的传输协议

- 发送端：将应用消息分成段（segments），传递到网络层
- 接收端rcv side：将段重新组合成消息，传递到应用层

### 多个传输协议可用于应用

- 互联网：TCP和UDP

### Transport vs. network layer

- 网络层：主机之间的逻辑通信

- 传输层：进程之间的逻辑通信（processes）

  从通信和信息处理的角度看，运输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。
  当网络的边缘部分中的两个主机使用网络的核心部分的功能进行端到端的通信时，只有位于网络边缘部分的主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。 
  两个主机进行通信实际上就是两个主机中的应用进程互相通信。 
  应用进程之间的通信又称为端到端的通信。 

  - 运输层的一个很重要的功能就是复用和分用。应用层不同进程的报文通过不同的端口向下交到运输层，再往下就共用网络层提供的服务。
  - “运输层提供应用进程间的逻辑通信”。“逻辑通信”的意思是：运输层之间的通信好像是沿水平方向传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。

- 传输层依赖(relies on)、增强(enhances)网络层服务

  - 依赖于网络层的服务 ：延时、带宽
  - 并对网络层的服务进行增强： 数据丢失、顺序混乱、加密
  - 有些服务是可以加强的：不可靠 -> 可靠；安全
  - 但有些服务是不可以被加强的：带宽，延迟

### 传输层的主要功能 

- 传输层为应用进程之间提供端到端的逻辑通信（但网络层是为主机之间提供逻辑通信）。
- 传输层还要对收到的报文进行差错检测。
- 传输层需要有两种不同的运输协议，即面向连接的 TCP 和无连接的 UDP。     

### 两种不同的运输协议

运输层向高层用户屏蔽了下面网络核心的细节（如网络拓扑、所采用的路由选择协议等），它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道。

- 当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的（只提供尽最大努力服务），但这种逻辑通信信道就相当于一条全双工的可靠信道。
- 当运输层采用无连接的 UDP 协议时，这种逻辑通信信道是一条不可靠信道。 
- TCP/IP 的传输层有两个不同的协议：

  - (1) 用户数据报协议 UDP	(User Datagram Protocol)
  - (2) 传输控制协议 TCP(Transmission Control Protocol)

### 协议特点：

- 可靠的有序交付 （TCP）

  - 拥塞控制congestion control 
  - 流控制flow control
  - 连接建立connection setup

- 不可靠、无序递交付（delivery）：UDP

  -  没有为尽力而为的IP服务添加更多的其它额外服务

- 不可用的服务：

  - 延迟保证delay guarantees
  - 带宽保证bandwidth guarantees

### TCP 与 UDP 

两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元 TPDU (Transport Protocol Data Unit)。
TCP 传送的数据单位协议是 TCP 报文段(segment)
UDP 传送的数据单位协议是 UDP 报文或用户数据报。 
UDP 在传送数据之前不需要先建立连接。对方的运输层在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 是一种最有效的工作方式。
TCP 则提供面向连接的服务。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。  
运输层的 UDP 用户数据报与网际层的IP数据报有很大区别。IP 数据报要经过互连网中许多路由器的存储转发，但 UDP 用户数据报是在运输层的端到端抽象的逻辑信道中传送的。
TCP 报文段是在运输层抽象的端到端逻辑信道中传送，这种信道是可靠的全双工信道。但这样的信道却不知道究竟经过了哪些路由器，而这些路由器也根本不知道上面的运输层是否建立了 TCP 连接。 

### 运输层的端口 

运行在计算机中的进程是用进程标识符来标志的。
运行在应用层的各种应用进程却不应当让计算机操作系统指派它的进程标识符。这是因为在因特网上使用的计算机的操作系统种类很多，而不同的操作系统又使用不同格式的进程标识符。
为了使运行不同操作系统的计算机的应用进程能够互相通信，就必须用统一的方法对 TCP/IP 体系的应用进程进行标志。 
解决这个问题的方法就是在运输层使用协议端口号(protocol port number)，或通常简称为端口(port)。
虽然通信的终点是应用进程，但我们可以把端口想象是通信的终点，因为我们只要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付目的进程）就由 TCP 来完成。

- 软件端口与硬件端口

  - 在协议栈层间的抽象的协议端口是软件端口。
  - 路由器或交换机上的端口是硬件端口。
  - 硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址。 

- TCP 的端口 

  - 端口用一个 16 位二进制端口号进行标志。0~65535
  - 端口号只具有本地意义，即端口号只是为了标志本计算机应用层中的各进程。在因特网中不同计算机的相同端口号是没有联系的。

- 三类端口 

  - 熟知端口，数值一般为 0~1023。
  - 登记端口号，数值为1024~49151，为没有熟知端口号的应用程序使用的。使用这个范围的端口号必须在 IANA 登记，以防止重复。
  - 客户端口号或短暂端口号，数值为49152~65535，留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的动态端口号。通信结束后，这个端口号可供其他客户进程以后使用。 

### 需要解决的问题 

- 由于进程的创建和撤销都是动态的，发送方几乎无法识别其他机器上的进程。
- 有时我们会改换接收报文的进程，但并不需要通知所有发送方。
- 我们往往需要利用目的主机提供的功能来识别终点，而不需要知道实现这个功能的进程。

### TCP 的连接 

- TCP 把连接作为最基本的抽象。
- 每一条 TCP 连接有两个端点。
- TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字(socket)或插口。
- 端口号拼接到(contatenated with) IP 地址即构成了套接字。   

  - 套接字 (socket)

    - 每一条 TCP 连接唯一地被通信两端的两个端点（即两个套接字）所确定。即：TCP 连接 ::= {socket1, socket2} = {(IP1: port1), (IP2: port2)}

  - socket的不同含义

    - 应用编程接口 API 称为 socket API, 简称为 socket。
    - socket API 中使用的一个函数名也叫作 socket。
    - 调用 socket 函数的端点称为 socket。
    - 调用 socket 函数时其返回值称为 socket 描述符，可简称为 socket。
    - 在操作系统内核中连网协议的 Berkeley 实现，称为 socket 实现。    

## 4.2 multiplexing and demultiplexing复用和解复用

### 复习：各层次的协议数据单元

### 解复用作用：TCP或者UDP实体采用哪些信息，将报文段的数据部分交给正确的socket，从而交给正确的进程

### 过程：

- 数据报格式
- 主机接收 IP 数据报

  - 每个数据报都有源 IP 地址、目的 IP 地址
  - 每个数据报携带 1 个传输层报文段（segment）
  - 每个segment都有源端口号和目标端口号（port number）

- 主机联合使用IP地址和端口号将报文段发送给合适的套接字

### Connectionless demultiplexing无连接解复用

- eg.左右两边的Client 应用 进程P3和P4向中间的Server 应用进程P1发送UDP 数据报。P4和P3发过来的UDP报文段的目标端口（destination port）都是6428 。
  即便P4和P3的源ip、源port不一样，但是都发给了中间服务器端口号为6428的、相同的应用进程。

  - 中间的Server 的进程P1给左右主机的进程P3、P4是如何发UDP数据报的

### Connection-oriented demultiplexing面向连接的多路复用

-  TCP套接字socket由四个元组标识

   - 源IP地址
   - 源端口号
   - 目的IP地址
   - 目的端口号

-  解复用：接收主机用这四个值来将数据报定位到合适的套接字
-  服务器能够在一个TCP端口上同时支持多个TCP套接字：

   - 每个套接字由其四元组标识（有不同的源IP和源PORT）

-  Web服务器对每个连接客户端有不同的套接字

   - 非持久对每个请求有不同的套接字

-  一个栗子：

   - 四元组就可以唯一确定一个TCP socket会话关系

## 4.3 connectionless transport: UDP 无连接传输UDP

### 介绍：

-  “尽力而为”的服务，报文段可能

   - 丢失
   - 送到应用进程的报文段乱序delivered out of order to app

-  无连接：

   - UDP发送端和接收端之间没有握手
   - 每个UDP报文段都被独立地处理

-  UDP 被用于:

   - 流媒体(streaming multimedia apps)（丢失不敏感-loss tolerant，速率敏感-rate sensitive，应用可控制传输速率）
   - DNS
   - SNMP

-  在UDP上可行可靠传输:

   - 在应用层增加可靠性
   - 应用特定的差错恢复（error recovery）

-  UDP为什么要有

   - 不建立连接（会增加延时）
   - 简单：在发送端和接收端无连接状态
   - 报文段的头部很小（开销小）
   - 无拥塞控制和流量控制

     - 应用->传输的速率=主机->网络的速率

### 面向报文的UDP

发送方 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。
应用层交给 UDP 多长的报文，UDP 就照样发送，即一次发送一个报文。
接收方 UDP 对 IP 层交上来的 UDP 用户数据报，在去除首部后就原封不动地交付上层的应用进程，一次交付一个完整的报文。
应用程序必须选择合适大小的报文。

- UDP 是面向报文的 
- UDP 的首部格式 
- UDP 基于端口的分用 

### UDP校验和checksum

- 目标：检测传输段中的“错误”（例如，翻转位flipped bits）
- EDC=error-detection and-correction 差错检测和纠错比特
- 发送端：

  - 将段内容视为 16 位整数的序列
  - 校验和：段内容的加法（补码和）
  - 发送方将校验和值放入 UDP 校验和字段中

- 接收端：

  - 计算已接收段的校验和
  - 检查计算的校验和是否等于校验和字段值：
  - 否 - 检测到错误

    - 发现错误UDP直接丢弃drop

  - 是 - 未检测到错误。但也许还是有错误，（错上加错，阴差阳错）

- 在计算检验和时，临时把“伪首部”和 UDP 用户数据报连接在一起。伪首部仅仅是为了计算检验和。
- 一个栗子：

  - 注意：将最高有效位循环加到最后一位上（必须将进位回卷到结果上）

## 4.4 principles of reliable data transfer可靠数据传输原理(rdt)

### TCP最主要的特点：

- TCP 是面向连接的运输层协议。

- 每一条 TCP 连接只能有两个端点(endpoint)，每一条 TCP 连接只能是点对点的（一对一）。 

- TCP 提供可靠交付的服务。

- TCP 提供全双工通信。

- 面向字节流。  

  - TCP面向流的概念

- 注意：

  TCP 连接是一条虚连接而不是一条真正的物理连接。
  TCP 对应用进程一次把多长的报文发送到TCP 的缓存中是不关心的。
  TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）。
  TCP 可把太长的数据块划分短一些再传送。TCP 也可等待积累有足够多的字节后再构成报文段发送出去。 

- TCP的连接

  TCP 把连接作为最基本的抽象。
  每一条 TCP 连接有两个端点。
  TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字(socket)或插口。
  端口号拼接到(contatenated with) IP 地址即构成了套接字。   

### rdt在应用层、传输层和数据链路层都很重要

- 信道的不可靠特点决定了可靠数据传输协议（rdt）的复杂性

### 传输层和应用层关系

### 可靠数据传输 问题描述：

- 渐增式（incrementally）地开发可靠数据传输协议（ rdt ）的发送方和接收方
- 只考虑单向数据传输，但控制信息是双向流动的
- 双向的数据传输问题实际上是2个单向数据传输问题的综合
- 使用有限状态机 (finite state machines, FSM) 来描述发送方和接收方

### Rdt1.0： 在可靠信道上的可靠数据传输

- 前提：下层信道是完全可靠的

  - 没有比特出错bit errors
  - 没有分组丢失loss of packets

- 发送方和接收方的FSM 

  - 发送方将数据发送到下层信道 
  - 接收方从下层信道接收数据

### Rdt2.0：具有比特差错的信道

- 下层信道可能会出错：将分组中的比特翻转

  - 用校验和来检测比特差错

- 问题：怎样从差错中恢复：

  - acknowledgements确认(ACK)：接收方显式地告诉发送方分组已被正确接收
  - negative acknowledgements否定确认( NAK): 接收方显式地告诉发送方分组发生了差错
  - 发送方收到NAK后，发送方重传分组

- rdt2.0中的新机制(mechanisms)（相较于rdt1.0）：采用差错控制编码进行差错检测

  - 发送方差错控制编码、缓存
  - 接收方使用编码检错
  - 接收方的反馈：控制报文（ACK，NAK）：接收方→发送方 
  - 发送方收到反馈相应的动作

- FSM描述

  - 没有差错时的操作
  - 有差错时error scenario

- rdt2.0的致命缺陷

  - 如果ACK/NAK出错(corrupted)？

    - 发送方不知道接收方发生了什么事情！
    - 发送方如何做？

      -  重传？可能重复
      -  不重传？可能死锁(或出错)

    - 需要引入新的机制

      - 序号sequence number 

  - 处理重复

    - 发送方在每个分组中加入序号(sequence number )
    - 如果ACK/NAK出错，发送方重传当前分组
    - 接收方丢弃（不发给上层）重复分组

  - 停等协议stop and wait

    - 发送方发送一个分组，然后等待接收方的应答，如果超过略大于“从发送方到接收方的平均往返时间”，就定为超时，然后重传。

    - 停止等待协议

      在发送完一个分组后，必须暂时保留已发送的分组的副本。
      分组和确认分组都必须进行编号。
      超时计时器的重传时间应当比数据在分组传输的平均往返时间更长一些。 

      - 确认丢失和确认迟到
      - 信道利用率很低，但是优点是简单

### Rdt2.1：处理出错(garbled)的ACK/NAK

- 发送方处理出错的ACK/NAK

- 接收方处理出错的ACK/NAK

- 讨论

  - 发送方

    - 在分组中加入序列号（seq #）
    - 两个序列号（0，1）就足够了

      - 一次只发送一个未经确认的分组

    - 必须检测ACK/NAK是否出错（需要EDC ）
    - FSM状态数变成了两倍

      - 必须记住当前分组的序列号为0还是1

  - 接收方

    - 必须检测接收到的分组是否是重复的

      - 状态会指示希望接收到的分组的序号为0还是1

    - 注意：接收方并不知道发送方是否正确收到了其ACK/NAK

      - 没有安排确认的确认 

- rdt2.1的运行

  发送方不对收到的ack/nak给确认 
  接收方发送ack，如果后面接收方收到的是： 
  老分组p0？则ack 错误 
  下一个分组？P1，ack正确 

### Rdt2.2: a NAK-free protocol无NAK的协议

- 功能同rdt2.1，但只使用ACK(ack 要编号）
- 接收方对最后正确接收的分组发ACK，以替代NAK

  - 接收方必须显式地(explicitly)包含被正确接收分组的序号

- 当收到重复的ACK（如：再次收到ack0）时，发送方与收到NAK采取相同的动作：重传当前分组
- 为后面的一次发送多个数据单位做一个准备

  - 一次能够发送多个
  - 每一个的应答都有：ACK，NACK；麻烦
  - 使用对前一个数据单位的ACK，代替本数据单位的nak
  - 确认信息减少一半，协议处理简单

- 发送方和接收方片断
- rdt2.2的运行

### Rdt3.0: channels with errors and loss具有比特差错和分组丢失的信道

- 新的假设

  - 下层信道可能会丢失分组（数据或ACK）

- 解决的问题：

  - 会死锁

  - 机制还不够处理这种状况

    检验和（checksum）
    序列号 （seq. #）
    ACK 
    重传 （会有所帮助，但是还不够）

- 方法：

  - 发送方等待ACK一段合理的时间

    此处合理的时间：链路层的timeout时间是确定的。传输层timeout时间是适应式的。

    - 发送端超时重传：如果到时没有收到ACK-》重传
    - 新的问题：如果分组（ACK）只是被延迟了？

      - 重传会导致数据重复，但利用序列号已经可以处理这个问题
      - 接收方必须指明被正确接受的序号

  - 解决新的问题：需要一个倒计数定时器(countdown timer)

    - 在给定的时间量过期后，可中断发送方

- rdt3.0发送方

  - 每次发送一个分组（包括第一次分组和重传分组）时，便启动一个定时器。
  - 响应定时器中断（采取适当的动作）
  - 中止定时器

- rdt3.0的运行

  - rdt3.0可以工作，但链路容量比较大的情况下，性能很差(performance stinks性能不好)

- rdt3.0的性能

  - 瓶颈在于：网络协议限制了物理资源的利用

$$
U_{sender}:利用率 ({\color{red} utilization})-忙于发送的时间比例(fraction of time sender busy sending)
$$

	- 

$$
T_{transmit}=\cfrac{L(分组长度packet length，比特)}{R(传输速度transmission rate，bps)}
$$

	- U为利用率

$$
U_{sender} = \cfrac{L/R}{RTT+L/R}
$$

- rdt3.0: stop-and-wait operation停-等操作
- 流水线协议Pipelined protocols：提高链路利用率

  - 允许发送方在未得到对方确认的情况下一次发送多个分组
  - 必须增加序号的范围:用多个bit表示分组的序号
  - 在发送方/接收方要有缓冲区

    - 发送方缓冲：未得到确认，可能需要重传；
    - 接收方缓存：上层用户取用数据的速率≠接收到的数据速率；接收到的数据可能乱序，排序交付（可靠）

  - 两种通用的流水线协议：

    - 回退N步(go-Back-N，GBN)
    - 选择重传(selective repeat，SR)

### 流水线协议Pipelined protocols：

发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。
由于信道上一直有数据不间断地传送，这种传输方式可获得很高的信道利用率

- Go-back-N和Selective Repeat对比（回退N步和选择重传对比）

  - 发送端发送数量（此点相同）
    一次都可以发送多个未经确认的分组

    - 发送端最多在流水线中有N个
      未确认的分组（unacked packets）
    - 发送端最多在流水线中
      有N个未确认的分组

  - ack对比

    - 接收方对每个到来的分组单独确认individual ack（非累计确认）
    - 接收端只是发送累计型确认cumulative ack
      （接收端如果发现gap，不确认新到来的分组）

  - 定时器对比

    - 发送方为每个未确认的分组保持一个定时器（当超时定时器到时，只是重发到时的未确认分组）
    - 发送端拥有对最早发送的的未确认分组的定时器（只需设置一个定时器，当定时器到时时，重传所有未确认分组）

  - 优点

    - 简单，所需资源少
      （接收方一个缓存单元）
    - 出错时，重传一个
      代价小

  - 缺点

    - 一旦出错，回退N步代价大 
    - 复杂，所需要资源多
      （接收方多个缓存单元）

  - 适用范围

    - 出错率低：比较适合GBN，出错非常罕见，没有必要用复杂的SR，为罕见的事件做日常的准备和复杂处理
    - 链路容量大（延迟大、带宽大）：比较适合SR而不是GBN，一点出错代价太大

  - 窗口的最大尺寸

    - SR:2^(n-1)
    - GBN: 2^n-1

- (Go-back-N,GBN)回退N步，也称为滑动窗口协议

  - 发送端

    - 分组标头中的k位序号
    - “window”最多 N （窗口长度）个，允许连续未确定的分组

  - 发送方扩展的FSM
  - 接收方扩展的FSM

    - 只发送ACK：对顺序接收的最高序号的分组

      - 可能会产生重复的ACK 
      - 只需记住（expectedseqnum）；接收窗口=1(只一个变量就可表示接收窗口)

    - 对乱序的分组：

      - 丢弃（不缓存） →在接收方不被缓存❗
      - 对顺序接收的最高序号的分组进行确认-累计确认

  - 运行中的GBN

- (SR,Selective Repeat)选择重传

  - 接收方对每个正确接收的分组，分别发送
    ACKn（非累积确认）

    - 接收窗口>1（可以缓存乱序的分组，根据需要缓存分组）
    - 最终将分组按顺序交付给上层

  - 发送方只对那些没有收到ACK的分组进行重发-选择性重发

    - 发送方为每个未确认的分组设定一个定时器

  - 发送窗口的最大值（发送缓冲区）限制发送未确认分组的个数
  - 发送方

    - 从上层接收数据

      - 如果下一个可用于该分组的序号可在发送窗口中，则发送

    - timeout(n):

      - 重新发送分组n，重新设定定时器

    - 

$$
ACK_{in [sendbase,sendbase+N]}:
$$

			- 将分组n标记为已接收
			- 如n为最小未确认的分组序号，将base移到下一个未确认序号
	
	- 接收方
	
		- 

$$
分组n_{[rcvbase, rcvbase+N-1]}
$$

			- 发送ACK(n)
			- 乱序：缓存
			- 有序：该分组及以前缓存的序号连续的分组交付给上层，然后将窗口移到下一个仍未被接收的分组
	
		- 

$$
分组n_{[rcvbase-N, rcvbase-1]}
$$

			- ACK(n)
	
		- 其它：
	
			- 忽略该分组
	
	- 接收方，发送方和接受windows示意图
	- 选择重传SR的运行（in action）
	
		- 两难情况（dilemma）
	
			- 接收器在两种情况下没有区别！
			- （b） 中接受为新数据的重复数据
			- 问：seq # 大小和窗口大小之间有什么关系，以避免 （b） 中出现问题？

### 可靠通信的实现

使用上述的确认和重传机制，我们就可以在不可靠的传输网络上实现可靠的通信。
这种可靠传输协议常称为自动重传请求ARQ (Automatic Repeat reQuest)。
ARQ 表明重传的请求是自动进行的。接收方不需要请求发送方重传某个出错的分组 。

- 连续 ARQ 协议 

  - Go-back-N协议表明当通信线路质量不好时，连续 ARQ 协议会带来负面的影响。 

- 累计确认

  接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认，而是对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。
  累积确认有的优点是：容易实现，即使确认丢失也不必重传。缺点是：不能向发送方反映出接收方已经正确收到的所有分组的信息。

- TCP可靠通信的具体实现

  TCP 连接的每一端都必须设有两个窗口——一个发送窗口和一个接收窗口。
  TCP 的可靠传输机制用字节的序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段。
  TCP 两端的四个窗口经常处于动态变化之中。
  TCP连接的往返时间 RTT 也不是固定不变的。需要使用特定的算法估算较为合理的重传时间。  

## 4.5 connection-oriented transport: TCP

点对点：  一个发送方，一个接收方
可靠的、按顺序的字节流：  没有报文边界（no "message boundaries"）
管道化（流水线pipelined）：TCP拥塞控制和流量控制设置，窗口大小
发送和接收缓存send & receive buffers
全双工数据full duplex data： 
在同一连接中数据流双向流动
MSS： maximum segment size最大报文段大小
面向连接：在数据交换之前，通过握手（交换控制报文） 初始化发送方、接收方的状态变量
有流量控制：发送方不会淹没（overwhelm）接收方 

### 4.5.1报文段结构segment structure

- 

  源端口和目的端口字段——各占 2 字节。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。 
  序号字段——占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。 
  确认号字段——占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。 
  数据偏移（即首部长度）——占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。“数据偏移”的单位是 32 位字（以 4 字节为计算单位）。  
  保留字段——占 6 位，保留为今后使用，但目前应置为 0。 
  紧急 URG —— 当 URG = 1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。
   确认 ACK —— 只有当 ACK = 1 时确认号字段才有效。当 ACK = 0 时，确认号无效。 
  推送 PSH (PuSH) —— 接收 TCP 收到 PSH = 1 的报文段，就尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。  
  复位 RST (ReSeT) —— 当 RST = 1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。 
  同步 SYN —— 同步 SYN = 1 表示这是一个连接请求或连接接受报文。 
  终止 FIN (FINis) —— 用来释放一个连接。FIN = 1 表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。
  窗口字段 —— 占 2 字节，用来让对方设置发送窗口的依据，单位为字节。 
  检验和 —— 占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。
  紧急指针字段 —— 占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。  
  选项字段 —— 长度可变。TCP 最初只规定了一种选项，即最大报文段长度 MSS。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节。” 
  MSS (Maximum Segment Size)是 TCP 报文段中的数据字段的最大长度。数据字段加上 TCP 首部才等于整个的 TCP 报文段。
  窗口扩大选项 ——占 3 字节，其中有一个字节表示移位值 S。新的窗口值等于TCP 首部中的窗口位数增大到(16 + S)，相当于把窗口值向左移动 S 位后获得实际的窗口大小。
  时间戳选项——占10 字节，其中最主要的字段时间戳值字段（4 字节）和时间戳回送回答字段（4 字节）。
  选择确认选项——在后面介绍。 
  填充字段 —— 这是为了使整个首部长度是 4 字节的整数倍。 

- TCP seq. numbers, ACKs序号、确认号

  - 序号sequence numbers：

    - 报文段首字节的在字节流的编号

  - 确认号acknowledgements:

    - 期望从另一方收到的下一个字节的序号（seq # ）
    - 累积（cumulative）确认

  - TCP不考虑接收方对乱序的报文段的排序问题
  - 

- TCP round trip time(往返延时, RTT), timeout(超时)

  - 怎样设置TCP超时的值？

    - 比RTT要长， 但RTT是变化的
    - 太短：太早(premature)超时→不必要的重传
    - 太长：对报文段丢失反应太慢

  - 怎样估计(estimate)RTT？

    - SampleRTT：测量从报文段发出到收到ack确认的时间（如果有重传，忽略此次测量）
    - SampleRTT会变化，因此估计的RTT应该比较平滑 → 对几个最近的测量值求平均，而不是仅用当前的SampleRTT

  - EstimatedRTT：加权平均往返时间
    指数加权(exponential weighted)移动平均
    过去样本的影响呈指数衰减
    推荐值：α = 0.125（0<α<1）

$$
EstimatedRTT = (1- \alpha)*EstimatedRTT + \alpha*SampleRTT
$$

		- TCP 保留了 RTT 的一个加权平均往返时间 RTTS（这又称为平滑的往返时间）。

第一次测量到 RTT 样本时，RTTS 值就取为所测量到的 RTT 样本值。以后每测量到一个新的 RTT 样本，就按下式重新计算一次 RTTS：

$$
新的 RTT_S = (1 - \alpha) * (旧的 RTT_S)                        + (\alpha * 新的 RTT 样本)
$$

			- 若 α  很接近于零，表示 RTT 值更新较慢。若选择 α  接近于 1，则表示 RTT 值更新较快。
			- RFC 2988 推荐的 α  值为 1/8，即 0.125。 
	
	- 设置超时时间
	
		- timeout interval超时间隔：EstimtedRTT + 安全边界(safety margin)时间：EstimatedRTT变化大 (方差大)→较大的安全边界时间
	
			- 往返时延的方差很大：由于 TCP 的下层是一个互联网环境，IP 数据报所选择的路由变化很大。因而运输层的往返时间的方差也很大。
	
		- SampleRTT会偏离EstimatedRTT多远：(推荐值：β = 0.25)

$$
DevRTT = (1-\beta)*DevRTT + \beta*|SampleRTT-EstimatedRTT|
$$

		  超时重传时间 RTO (RetransmissionTime-Out) 
		  RTO 应略大于上面得出的加权平均往返时间 RTTS。
		  RFC 2988 建议使用下式计算 RTO：
		   RTO = RTTS + 4 * RTTD                  
		  RTTD 是 RTT 的偏差的加权平均值。
		  RFC 2988 建议这样计算 RTTD。第一次测量时，RTTD 值取为测量到的 RTT 样本值的一半。在以后的测量中，则使用下式计算加权平均的RTTD：
		  新的RTTD = (1 - β) * (旧的RTTD)  + β*RTTS|新的RTT样本| 
		  β是个小于 1 的系数，其推荐值是 1/4，即 0.25。
		  
		- 
		- 超时重传时间的选择：TCP 每发送一个报文段，就对这个报文段设置一次计时器。只要计时器设置的重传时间到但还没有收到确认，就要重传这一报文段。
	
	- 往返时间的测量相当复杂 
	
	  TCP 报文段 1 没有收到确认。重传（即报文段 2）后，收到了确认报文段 ACK。 
	  如何判定此确认报文段是对原来的报文段 1 的确认，还是对重传的报文段 2 的确认？ 
	  
		- Karn 算法
	
			- 在计算平均往返时间 RTT 时，只要报文段重传了，就不采用其往返时间样本。
			- 这样得出的加权平均平均往返时间 RTTS 和超时重传时间 RTO 就较准确。 
	
		- 修正的 Karn 算法 
	
		  报文段每重传一次，就把 RTO 增大一些： 
		  新的 RTO = γ *  (旧的 RTO) 
		  系数 γ的典型值是 2 。 
		  当不再发生报文段的重传时，才根据报文段的往返时延更新平均往返时延 RTT 和超时重传时间 RTO 的数值。 
		  实践证明，这种策略较为合理。 


​		  

	- 选择确认 SACK(Selective ACK) 
	
	  接收方收到了和前面的字节流不连续的两个字节块。 
	  如果这些字节的序号都在接收窗口之内，那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些已收到的数据。 


​	  

		- RCF2018的规定
	
		  如果要使用选择确认，那么在建立 TCP 连接时，就要在 TCP 首部的选项中加上“允许 SACK”的选项，而双方必须都事先商定好。 
		  如果使用选择确认，那么原来首部中的“确认号字段”的用法仍然不变。只是以后在 TCP 报文段的首部中都增加了 SACK 选项，以便报告收到的不连续的字节块的边界。 
		  由于首部选项的长度最多只有 40 字节，而指明一个边界就要用掉 4 字节，因此在选项中最多只能指明 4 个字节块的边界信息。 


​		  

		- 

- TCP可靠传输的实现：以字节为单位的滑动窗口

  - 

    - 

      - 

  - 发送缓存
  - 接收缓存
  - 注意：

    - A 的发送窗口并不总是和 B 的接收窗口一样大（因为有一定的时间滞后）。
    - TCP 标准没有规定对不按序到达的数据应如何处理。通常是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。
    - TCP 要求接收方必须有累积确认的功能，这样可以减小传输开销。  

### 4.5.2 TCP：reliable data transfer可靠数据传输

- 概述

  - TCP在IP不可靠服务的基础上建立了rdt 

    - 管道化的报文段(GBN or SR)
    - 累积确认（像GBN）
    - 单个重传定时器（像GBN）

  - 通过以下事件触发重传

    - 超时（只重发那个最早的未确认段：SR）
    - 重复的确认 

  - 首先考虑简化的TCP发送方：

    - 忽略重复的确认
    - 忽略流量控制和拥塞控制

- TCP sender events发送方事件：

  - 从应用层接收数据：

    - 用nextseq创建报文段
    - 序号nextseq为报文段首字节的字节流编号
    - 如果还没有运行，启动定时器

      - 定时器与最早未确认的报文段关联
      - 过期间隔(expiration interval)：TimeOutInterval

  - 超时：

    - 重传导致超时的报文段
    - 重新启动定时器

  - 收到确认：

    - 如果是对尚未确认的报文段确认

      - 更新已被确认的报文序号
      - 如果当前还有未被确认的报文段，重新启动定时器

  - 简化的状态图

    - TCP重传场景

  - 

- TCP fast retransmit快速重传

  - 超时周期往往太长：在重传丢失报文段之前的
    延时太长
  - 通过重复的ACK来检测报文段丢失

    - 发送方通常连续发送大量报文段
    - 如果报文段丢失，通常会引起多个重复的ACK
    - 原因：如果发送方收到同一数据的3个冗余ACK，重传最小序号的段： 

      - 快速重传：在定时器过时之前重发报文段
        它假设跟在被确认的数据后面的数据丢失了
        第一个ACK是正常的；
        收到第二个该段的ACK，表示接收方收到一个该段后的乱序段；
        收到第3，4个该段的ack，表示接收方收到该段之后的2个，3个乱序段，可能性非常大，段丢失了，无需再等到时延后再重传

### 4.5.3 TCP flow control流量控制

- 接收方控制发送方，不让发送方发的太多太快以至于让接收方的缓冲区溢出

  - 缓冲区TCP往里面写，app从当中读取

- 实现原理：接收方在其向发送方的TCP段头部的rwnd字段“通告”其空闲buffer大小
  发送端将未确认的数据限制为RcvWindow
  Rcvr（接收端）在大于RcvWindow的段找可用空间？？？

  - 虽然达到流量控制，但是应用进程从缓冲区读取时可能会很慢
  - 速度匹配服务：将发送速率与接收应用的消耗速率相匹配
  - 假设TCP接收端丢弃无序报文段时
    缓存中可用的空间=RcvWindow
    = RcvBuffer-[LastByteRcvd - LastByteRead]

- 利用滑动窗口实现流量控制

  一般说来，我们总是希望数据传输得更快一些。但如果发送方把数据发送得过快，接收方就可能来不及接收，这就会造成数据的丢失。 
  流量控制(flow control)就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。 
  利用滑动窗口机制可以很方便地在 TCP 连接上实现流量控制。 


  - 流量控制举例

- 持续计时器(persistence timer)

  TCP 为每一个连接设有一个持续计时器。 
  只要 TCP 连接的一方收到对方的零窗口通知，就启动持续计时器。 
  若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带 1 字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。 
  若窗口仍然是零，则收到这个报文段的一方就重新设置持续计时器。 
  若窗口不是零，则死锁的僵局就可以打破了。 

- 必须考虑传输效率

  可以用不同的机制来控制 TCP 报文段的发送时机: 
  第一种机制是 TCP 维持一个变量，它等于最大报文段长度 MSS。只要缓存中存放的数据达到 MSS 字节时，就组装成一个 TCP 报文段发送出去。 
  第二种机制是由发送方的应用进程指明要求发送报文段，即 TCP 支持的推送(push)操作。 
  第三种机制是发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段（但长度不能超过 MSS）发送出去。 

  

### 4.5.4 connection management连接管理

- Recall：TCP发送方、接收方在交换数据段前建立“连接”

  - 初始化TCP变量

    - 序号seq.#s
    - 缓冲区、流量控制信息（eg.Rcvwindow）

  - 客户端：连接启动器（connection initiator）

    - Socket clientSocket = new Socket("hostname","port number"); 

  - 服务器：由客户联系

    - Socket connectionSocket = welcomeSocket.accept();

- 3次握手

  - 步骤 1：客户端主机将 TCP SYN 段发送到服务器

    - 指定初始序号seq#
    - 无数据

  - 步骤2：服务器主机接收SYN，使用SYNACK段回复

    - 服务器分配缓冲区
    - 指定服务器初始 seq.#

  - 步骤3：客户端接收SYNACK，使用ACK段回复，其中可能包含数据

- 在正式交换数据之前，发送方和接收方握手建立通信关系:

  - 同意建立连接（每一方都知道对方愿意建立连接）
  - 同意连接参数 

- Agreeing to establish a connection同意建立连接

  - 两次握手不总是可以确保建立连接

    - 变化的延迟（连接请求的段没有丢，但可能超时）
    - 由于丢失造成的重传 (e.g.req_conn(x))
    - 报文乱序
    - 相互看不到对方
    - 一个栗子

  - 3次握手

    - 解决的问题：半连接和接收老数据问题
    - 3次握手：FSM

- TCP: 关闭连接closing a connection

  - 客户端，服务器分别关闭它自己这一侧的连接

    - 发送FIN bit = 1的TCP段

  - 一旦接收到FIN，用ACK回应

    - 接到FIN段，ACK可以和它自己发出的FIN段一起发送

  - 可以处理同时(simultaneous)的FIN交换 

### 总结：

- 1.  运输连接的三个阶段 

  运输连接就有三个阶段，即：连接建立、数据传送和连接释放。运输连接的管理就是使运输连接的建立和释放都能正常地进行。 
  连接建立过程中要解决以下三个问题： 
  要使每一方能够确知对方的存在。 
  要允许双方协商一些参数（如最大报文段长度，最大窗口大小，服务质量等）。 
  能够对运输实体资源（如缓存大小，连接表中的项目等）进行分配。 

- 客户服务器方式

  TCP 连接的建立都是采用客户服务器方式。 
  主动发起连接建立的应用进程叫做客户(client)。 
  被动等待连接建立的应用进程叫做服务器(server)。 

- 过程：握手、连接释放PPT p164-177

  - A 必须等待 2MSL 的时间

    第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B。 
    第二，防止 “已失效的连接请求报文段”出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段，都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。 

## 4.6 principles of congestion control拥塞控制原理

### 拥塞:

- 非正式的定义: “太多的数据需要网络传输，超过了网络的处理能力”
- 与流量控制不同
- 拥塞的表现manifestations:

  - 分组丢失 (路由器缓冲区溢出)
  - 分组经历比较长的延迟(在路由器的队列中排队)

- 拥塞的原因/代价: 场景(scenario)1
- 拥塞的原因/代价: 场景2

  - 

    - 

  - 

    - retrans（重传）

- 拥塞的原因/代价: 场景3

  - 

### 拥塞控制方法

- 端到端拥塞控制:

  - 没有来自网络的显式反馈
  - 端系统根据延迟和丢失事件推断是否有拥塞
  - TCP采用的方法

- 网络辅助的拥塞控制:

  - 路由器提供给端系统以反馈信息
  - 单个bit置位，显示有拥塞 (SNA, DECbit,TCP/IP ECN, ATM)
  - 显式提供发送端可以采用的速率

## 4.7 TCP congestion control（TCP拥塞控制）

### TCP 拥塞控制：AIMD（additive increase multiplication decrease）加性增，乘性减

- 方法：发送方提高传输速率（窗口大小），探测可用带宽，直到发生丢失

  如何控制发送端发送的速率
  维持一个拥塞窗口的值：CongWin（cwnd）
  发送端限制已发送但是未确认的数据量（的上限）: LastByteSent-LastByteAcked ≤ CongWin
  从而粗略地控制发送方的往网络中注入的速率

  - 加法增加：
    当CongWin>阈值时，一个RTT如没有发生丢失事件 ,将CongWin加1MSS: 探测
  - 乘法减少:
    丢失事件后将CongWin降为1，将CongWin/2作为阈值，进入慢启动阶段（倍增直到CongWin/2）
  - cwnd是动态的，有感知网络拥塞的功能
  - TCP发送速率：
    大致就是cwnd字节，等待RTT的ACKS，然后发送更多字节

### TCP慢启动

- 当连接开始时，指数性增加（每个RTT）发送速率直到发生丢失事件

  - 连接刚建立, CongWin = 1MSS
  - 每一个RTT， CongWin加倍
  - 每收到一个ACK时，CongWin加1（why）
  - 慢启动阶段：只要不超时或3个重复ack，一个RTT， CongWin加倍

- 总结: 初始速率很慢，但是加速却是指数性的

  - 指数增加，SS时间很短，长期来看可以忽略

### TCP：detecting, reacting to loss

检测、对丢失的反应

- loss indicated by timeout
  超时指示的损失：

  - 1.cwnd 设置为 1 MSS;
  - 2.然后窗口呈指数级增长（exponentially）（如在慢启动时）到阈值（threshold），然后线性（linearly）增长

- 由 3 个重复的 ACK 指示的丢失：TCP RENO

  - dup ACK 表示网络能够提供某些网段
  - cwnd被切成两半的窗口，然后线性增长

- TCP Tahoe 始终将 cwnd 设置为 1（超时timeout或 3 个重复的 ack）

### TCP：从慢启动切换到 CA（switching from slow start to CA）

- 问：指数增长何时应切换到线性？
  答：当cwnd在超时之前达到其值的1/2时。
- 实现：通过可变的ssthresh
  在loss事件时，ssthresh 设置为亏损事件发生前 cwnd 的 1/2

### 总结：

### TCP吞吐量throughput

- TCP的平均吞吐量是多少，使用窗口window尺寸W和RTT来描述?
  忽略慢启动阶段，假设发送端总有数据传输
- 

### 

### TCP公平性fairness

- 公平性目标goal：

  - 如果 K个TCP会话分享一个链路带宽为R的瓶颈，每一个会话的有效带宽为 R/K

- TCP公平的原因

  - 

### Explicit Congestion Notification (ECN)

- 网络辅助拥塞控制:

  TOS字段中2个bit被网络路由器标记，用于指示是否发 生拥塞
  拥塞指示被传送到接收主机
  在接收方-到发送方的ACK中，接收方(在IP数据报中看到了拥塞指示）设置ECE bit，指示发送方发生了拥塞 

## 总结：

### 拥塞控制的一般原理 

在某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏——产生拥塞(congestion)。 
出现资源拥塞的条件： 对资源需求的总和 > 可用资源 
若网络中有许多资源同时产生拥塞，网络的性能就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。 

拥塞控制是很难设计的，因为它是一个动态的（而不是静态的）问题。 
当前网络正朝着高速化的方向发展，这很容易出现缓存不够大而造成分组的丢失。但分组的丢失是网络发生拥塞的征兆而不是原因。 
在许多情况下，甚至正是拥塞控制本身成为引起网络性能恶化甚至发生死锁的原因。这点应特别引起重视。 


### 拥塞控制与流量控制的关系 

拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。 
拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。 
流量控制往往指在给定的发送端和接收端之间的点对点通信量的控制。 
流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 


### 开环控制和闭环控制

开环控制方法就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。 
闭环控制是基于反馈环路的概念。属于闭环控制的有以下几种措施： 
监测网络系统以便检测到拥塞在何时、何处发生。 
将拥塞发生的信息传送到可采取行动的地方。 
调整网络系统的运行以解决出现的问题。 

### 几种拥塞控制方法

- 1.  慢开始和拥塞避免

  发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。如再考虑到接收方的接收能力，则发送窗口还可能小于拥塞窗口。 
  发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 


  - 慢开始算法原理

    在主机刚刚开始发送报文段时可先设置拥塞窗口 cwnd = 1，即设置为一个最大报文段 MSS 的数值。 
    在每收到一个对新的报文段的确认后，将拥塞窗口加 1，即增加一个 MSS 的数值。 
    用这样的方法逐步增大发送端的拥塞窗口 cwnd，可以使分组注入到网络的速率更加合理。 

  - 传输轮次(transmission round)

    使用慢开始算法后，每经过一个传输轮次，拥塞窗口 cwnd 就加倍。 
    一个传输轮次所经历的时间其实就是往返时间 RTT。 
    “传输轮次”更加强调：把拥塞窗口 cwnd 所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 
    例如，拥塞窗口 cwnd = 4，这时的往返时间 RTT 就是发送方连续发送 4 个报文段，并收到这 4 个报文段的确认，总共经历的时间。 

  - 设置慢开始门限状态变量ssthresh

    慢开始门限 ssthresh 的用法如下： 
    当 cwnd < ssthresh 时，使用慢开始算法。 
    当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 
    当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。 
    拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。 

  - 当网络出现拥塞时

    无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认），就要把慢开始门限 ssthresh 设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。 
    然后把拥塞窗口 cwnd 重新设置为 1，执行慢开始算法。 
    这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 

  - 慢开始和拥塞避免算法的实现举例 

    当 TCP 连接进行初始化时，将拥塞窗口置为 1。图中的窗口单位不使用字节而使用报文段。 
    慢开始门限的初始值设置为 16 个报文段， 
    即 ssthresh = 16。 
    发送端的发送窗口不能超过拥塞窗口 cwnd 和接收端窗口 rwnd 中的最小值。我们假定接收端窗口足够大，因此现在发送窗口的数值等于拥塞窗口的数值。 
    在执行慢开始算法时，拥塞窗口 cwnd 的初始值为 1，发送第一个报文段 M0。 
    发送端每收到一个确认 ，就把 cwnd 加 1。于是发送端可以接着发送 M1 和 M2 两个报文段。 
    接收端共发回两个确认。发送端每收到一个对新报文段的确认，就把发送端的 cwnd 加 1。现在 cwnd 从 2 增大到 4，并可接着发送后面的 4 个报文段。 
    发送端每收到一个对新报文段的确认，就把发送端的拥塞窗口加 1，因此拥塞窗口 cwnd 随着传输轮次按指数规律增长。
    当拥塞窗口 cwnd 增长到慢开始门限值 ssthresh 时（即当 cwnd = 16 时），就改为执行拥塞避免算法，拥塞窗口按线性规律增长。 
    假定拥塞窗口的数值增长到 24 时，网络出现超时，表明网络拥塞了。 
    更新后的 ssthresh 值变为 12（即发送窗口数值 24 的一半），拥塞窗口再重新设置为 1，并执行慢开始算法。 
    当 cwnd = 12 时改为执行拥塞避免算法，拥塞窗口按按线性规律增长，每经过一个往返时延就增加一个 MSS 的大小。 

  - 乘法减小(multiplicative decrease) 

    “乘法减小“是指不论在慢开始阶段还是拥塞避免阶段，只要出现一次超时（即出现一次网络拥塞），就把慢开始门限值 ssthresh 设置为当前的拥塞窗口值乘以 0.5。 
    当网络频繁出现拥塞时，ssthresh 值就下降得很快，以大大减少注入到网络中的分组数。 

  - 加法增大(additive increase) 

    “加法增大”是指执行拥塞避免算法后，在收到对所有报文段的确认后（即经过一个往返时间），就把拥塞窗口 cwnd增加一个 MSS 大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。 

  - “拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。

“拥塞避免”是说在拥塞避免阶段把拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。 

- 2.  快重传和快恢复

  快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认。这样做可以让发送方及早知道有报文段没有到达接收方。 
  发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段。 
  不难看出，快重传并非取消重传计时器，而是在某些情况下可更早地重传丢失的报文段。 


  - 快重传举例

  - 快恢复算法

    (1) 当发送端收到连续三个重复的确认时，就执行“乘法减小”算法，把慢开始门限 ssthresh 减半。但接下去不执行慢开始算法。 
    (2)由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，即拥塞窗口 cwnd 现在不设置为 1，而是设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。 

  - 发送窗口的上限值

    发送方的发送窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，即应按以下公式确定： 发送窗口的上限值 = Min [rwnd, cwnd] 
    当 rwnd < cwnd 时，是接收方的接收能力限制发送窗口的最大值。 
    当 cwnd < rwnd 时，则是网络的拥塞限制发送窗口的最大值。 

### 随机早期检测 RED (Random Early Detection) 

使路由器的队列维持两个参数，即队列长度最小门限 THmin 和最大门限 THmax。 
RED 对每一个到达的数据报都先计算平均队列长度 LAV。 
若平均队列长度小于最小门限 THmin，则将新到达的数据报放入队列进行排队。 
若平均队列长度超过最大门限 THmax，则将新到达的数据报丢弃。 
若平均队列长度在最小门限 THmin 和最大门限THmax 之间，则按照某一概率 p 将新到达的数据报丢弃。 

- 

  - 



​	因为知识点很多，这部分的笔记最开始是用思维导图记的，但是图片都不能导出，xmind格式的到[百度网盘](https://pan.baidu.com/s/1nelcbTiZayBHzq38YnH5Pg?pwd=hlr4)自行下载或者联系我私发叭，笔记效果如下（也不是那么好看，建议还是看PPT或者自己整理效率较高，我的笔记整理效果稍稍欠缺）：

{% markmap 800px %}

# 第四章、传输层

## 4.1 transport-layer services

### 在不同主机上运行的应用进程之间提供逻辑通信（logical communication）

### 在终端系统中运行的传输协议

- 发送端：将应用消息分成段（segments），传递到网络层
- 接收端rcv side：将段重新组合成消息，传递到应用层

### 多个传输协议可用于应用

- 互联网：TCP和UDP

### Transport vs. network layer

- 网络层：主机之间的逻辑通信

- 传输层：进程之间的逻辑通信（processes）

  从通信和信息处理的角度看，运输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。
  当网络的边缘部分中的两个主机使用网络的核心部分的功能进行端到端的通信时，只有位于网络边缘部分的主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。 
  两个主机进行通信实际上就是两个主机中的应用进程互相通信。 
  应用进程之间的通信又称为端到端的通信。 

  - 运输层的一个很重要的功能就是复用和分用。应用层不同进程的报文通过不同的端口向下交到运输层，再往下就共用网络层提供的服务。
  - “运输层提供应用进程间的逻辑通信”。“逻辑通信”的意思是：运输层之间的通信好像是沿水平方向传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。

- 传输层依赖(relies on)、增强(enhances)网络层服务

  - 依赖于网络层的服务 ：延时、带宽
  - 并对网络层的服务进行增强： 数据丢失、顺序混乱、加密
  - 有些服务是可以加强的：不可靠 -> 可靠；安全
  - 但有些服务是不可以被加强的：带宽，延迟

### 传输层的主要功能 

- 传输层为应用进程之间提供端到端的逻辑通信（但网络层是为主机之间提供逻辑通信）。
- 传输层还要对收到的报文进行差错检测。
- 传输层需要有两种不同的运输协议，即面向连接的 TCP 和无连接的 UDP。     

### 两种不同的运输协议

运输层向高层用户屏蔽了下面网络核心的细节（如网络拓扑、所采用的路由选择协议等），它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道。

- 当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的（只提供尽最大努力服务），但这种逻辑通信信道就相当于一条全双工的可靠信道。
- 当运输层采用无连接的 UDP 协议时，这种逻辑通信信道是一条不可靠信道。 
- TCP/IP 的传输层有两个不同的协议：

  - (1) 用户数据报协议 UDP	(User Datagram Protocol)
  - (2) 传输控制协议 TCP(Transmission Control Protocol)

### 协议特点：

- 可靠的有序交付 （TCP）

  - 拥塞控制congestion control 
  - 流控制flow control
  - 连接建立connection setup

- 不可靠、无序递交付（delivery）：UDP

  -  没有为尽力而为的IP服务添加更多的其它额外服务

- 不可用的服务：

  - 延迟保证delay guarantees
  - 带宽保证bandwidth guarantees

### TCP 与 UDP 

两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元 TPDU (Transport Protocol Data Unit)。
TCP 传送的数据单位协议是 TCP 报文段(segment)
UDP 传送的数据单位协议是 UDP 报文或用户数据报。 
UDP 在传送数据之前不需要先建立连接。对方的运输层在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 是一种最有效的工作方式。
TCP 则提供面向连接的服务。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。  
运输层的 UDP 用户数据报与网际层的IP数据报有很大区别。IP 数据报要经过互连网中许多路由器的存储转发，但 UDP 用户数据报是在运输层的端到端抽象的逻辑信道中传送的。
TCP 报文段是在运输层抽象的端到端逻辑信道中传送，这种信道是可靠的全双工信道。但这样的信道却不知道究竟经过了哪些路由器，而这些路由器也根本不知道上面的运输层是否建立了 TCP 连接。 

### 运输层的端口 

运行在计算机中的进程是用进程标识符来标志的。
运行在应用层的各种应用进程却不应当让计算机操作系统指派它的进程标识符。这是因为在因特网上使用的计算机的操作系统种类很多，而不同的操作系统又使用不同格式的进程标识符。
为了使运行不同操作系统的计算机的应用进程能够互相通信，就必须用统一的方法对 TCP/IP 体系的应用进程进行标志。 
解决这个问题的方法就是在运输层使用协议端口号(protocol port number)，或通常简称为端口(port)。
虽然通信的终点是应用进程，但我们可以把端口想象是通信的终点，因为我们只要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付目的进程）就由 TCP 来完成。

- 软件端口与硬件端口

  - 在协议栈层间的抽象的协议端口是软件端口。
  - 路由器或交换机上的端口是硬件端口。
  - 硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址。 

- TCP 的端口 

  - 端口用一个 16 位二进制端口号进行标志。0~65535
  - 端口号只具有本地意义，即端口号只是为了标志本计算机应用层中的各进程。在因特网中不同计算机的相同端口号是没有联系的。

- 三类端口 

  - 熟知端口，数值一般为 0~1023。
  - 登记端口号，数值为1024~49151，为没有熟知端口号的应用程序使用的。使用这个范围的端口号必须在 IANA 登记，以防止重复。
  - 客户端口号或短暂端口号，数值为49152~65535，留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的动态端口号。通信结束后，这个端口号可供其他客户进程以后使用。 

### 需要解决的问题 

- 由于进程的创建和撤销都是动态的，发送方几乎无法识别其他机器上的进程。
- 有时我们会改换接收报文的进程，但并不需要通知所有发送方。
- 我们往往需要利用目的主机提供的功能来识别终点，而不需要知道实现这个功能的进程。

### TCP 的连接 

- TCP 把连接作为最基本的抽象。
- 每一条 TCP 连接有两个端点。
- TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字(socket)或插口。
- 端口号拼接到(contatenated with) IP 地址即构成了套接字。   

  - 套接字 (socket)

    - 每一条 TCP 连接唯一地被通信两端的两个端点（即两个套接字）所确定。即：TCP 连接 ::= {socket1, socket2} = {(IP1: port1), (IP2: port2)}

  - socket的不同含义

    - 应用编程接口 API 称为 socket API, 简称为 socket。
    - socket API 中使用的一个函数名也叫作 socket。
    - 调用 socket 函数的端点称为 socket。
    - 调用 socket 函数时其返回值称为 socket 描述符，可简称为 socket。
    - 在操作系统内核中连网协议的 Berkeley 实现，称为 socket 实现。    

## 4.2 multiplexing and demultiplexing复用和解复用

### 复习：各层次的协议数据单元

### 解复用作用：TCP或者UDP实体采用哪些信息，将报文段的数据部分交给正确的socket，从而交给正确的进程

### 过程：

- 数据报格式
- 主机接收 IP 数据报

  - 每个数据报都有源 IP 地址、目的 IP 地址
  - 每个数据报携带 1 个传输层报文段（segment）
  - 每个segment都有源端口号和目标端口号（port number）

- 主机联合使用IP地址和端口号将报文段发送给合适的套接字

### Connectionless demultiplexing无连接解复用

- eg.左右两边的Client 应用 进程P3和P4向中间的Server 应用进程P1发送UDP 数据报。P4和P3发过来的UDP报文段的目标端口（destination port）都是6428 。
  即便P4和P3的源ip、源port不一样，但是都发给了中间服务器端口号为6428的、相同的应用进程。

  - 中间的Server 的进程P1给左右主机的进程P3、P4是如何发UDP数据报的

### Connection-oriented demultiplexing面向连接的多路复用

-  TCP套接字socket由四个元组标识

   - 源IP地址
   - 源端口号
   - 目的IP地址
   - 目的端口号

-  解复用：接收主机用这四个值来将数据报定位到合适的套接字
-  服务器能够在一个TCP端口上同时支持多个TCP套接字：

   - 每个套接字由其四元组标识（有不同的源IP和源PORT）

-  Web服务器对每个连接客户端有不同的套接字

   - 非持久对每个请求有不同的套接字

-  一个栗子：

   - 四元组就可以唯一确定一个TCP socket会话关系

## 4.3 connectionless transport: UDP 无连接传输UDP

### 介绍：

-  “尽力而为”的服务，报文段可能

   - 丢失
   - 送到应用进程的报文段乱序delivered out of order to app

-  无连接：

   - UDP发送端和接收端之间没有握手
   - 每个UDP报文段都被独立地处理

-  UDP 被用于:

   - 流媒体(streaming multimedia apps)（丢失不敏感-loss tolerant，速率敏感-rate sensitive，应用可控制传输速率）
   - DNS
   - SNMP

-  在UDP上可行可靠传输:

   - 在应用层增加可靠性
   - 应用特定的差错恢复（error recovery）

-  UDP为什么要有

   - 不建立连接（会增加延时）
   - 简单：在发送端和接收端无连接状态
   - 报文段的头部很小（开销小）
   - 无拥塞控制和流量控制

     - 应用->传输的速率=主机->网络的速率

### 面向报文的UDP

发送方 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。
应用层交给 UDP 多长的报文，UDP 就照样发送，即一次发送一个报文。
接收方 UDP 对 IP 层交上来的 UDP 用户数据报，在去除首部后就原封不动地交付上层的应用进程，一次交付一个完整的报文。
应用程序必须选择合适大小的报文。

- UDP 是面向报文的 
- UDP 的首部格式 
- UDP 基于端口的分用 

### UDP校验和checksum

- 目标：检测传输段中的“错误”（例如，翻转位flipped bits）
- EDC=error-detection and-correction 差错检测和纠错比特
- 发送端：

  - 将段内容视为 16 位整数的序列
  - 校验和：段内容的加法（补码和）
  - 发送方将校验和值放入 UDP 校验和字段中

- 接收端：

  - 计算已接收段的校验和
  - 检查计算的校验和是否等于校验和字段值：
  - 否 - 检测到错误

    - 发现错误UDP直接丢弃drop

  - 是 - 未检测到错误。但也许还是有错误，（错上加错，阴差阳错）

- 在计算检验和时，临时把“伪首部”和 UDP 用户数据报连接在一起。伪首部仅仅是为了计算检验和。
- 一个栗子：

  - 注意：将最高有效位循环加到最后一位上（必须将进位回卷到结果上）

## 4.4 principles of reliable data transfer可靠数据传输原理(rdt)

### TCP最主要的特点：

- TCP 是面向连接的运输层协议。

- 每一条 TCP 连接只能有两个端点(endpoint)，每一条 TCP 连接只能是点对点的（一对一）。 

- TCP 提供可靠交付的服务。

- TCP 提供全双工通信。

- 面向字节流。  

  - TCP面向流的概念

- 注意：

  TCP 连接是一条虚连接而不是一条真正的物理连接。
  TCP 对应用进程一次把多长的报文发送到TCP 的缓存中是不关心的。
  TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）。
  TCP 可把太长的数据块划分短一些再传送。TCP 也可等待积累有足够多的字节后再构成报文段发送出去。 

- TCP的连接

  TCP 把连接作为最基本的抽象。
  每一条 TCP 连接有两个端点。
  TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字(socket)或插口。
  端口号拼接到(contatenated with) IP 地址即构成了套接字。   

### rdt在应用层、传输层和数据链路层都很重要

- 信道的不可靠特点决定了可靠数据传输协议（rdt）的复杂性

### 传输层和应用层关系

### 可靠数据传输 问题描述：

- 渐增式（incrementally）地开发可靠数据传输协议（ rdt ）的发送方和接收方
- 只考虑单向数据传输，但控制信息是双向流动的
- 双向的数据传输问题实际上是2个单向数据传输问题的综合
- 使用有限状态机 (finite state machines, FSM) 来描述发送方和接收方

### Rdt1.0： 在可靠信道上的可靠数据传输

- 前提：下层信道是完全可靠的

  - 没有比特出错bit errors
  - 没有分组丢失loss of packets

- 发送方和接收方的FSM 

  - 发送方将数据发送到下层信道 
  - 接收方从下层信道接收数据

### Rdt2.0：具有比特差错的信道

- 下层信道可能会出错：将分组中的比特翻转

  - 用校验和来检测比特差错

- 问题：怎样从差错中恢复：

  - acknowledgements确认(ACK)：接收方显式地告诉发送方分组已被正确接收
  - negative acknowledgements否定确认( NAK): 接收方显式地告诉发送方分组发生了差错
  - 发送方收到NAK后，发送方重传分组

- rdt2.0中的新机制(mechanisms)（相较于rdt1.0）：采用差错控制编码进行差错检测

  - 发送方差错控制编码、缓存
  - 接收方使用编码检错
  - 接收方的反馈：控制报文（ACK，NAK）：接收方→发送方 
  - 发送方收到反馈相应的动作

- FSM描述

  - 没有差错时的操作
  - 有差错时error scenario

- rdt2.0的致命缺陷

  - 如果ACK/NAK出错(corrupted)？

    - 发送方不知道接收方发生了什么事情！
    - 发送方如何做？

      -  重传？可能重复
      -  不重传？可能死锁(或出错)

    - 需要引入新的机制

      - 序号sequence number 

  - 处理重复

    - 发送方在每个分组中加入序号(sequence number )
    - 如果ACK/NAK出错，发送方重传当前分组
    - 接收方丢弃（不发给上层）重复分组

  - 停等协议stop and wait

    - 发送方发送一个分组，然后等待接收方的应答，如果超过略大于“从发送方到接收方的平均往返时间”，就定为超时，然后重传。

    - 停止等待协议

      在发送完一个分组后，必须暂时保留已发送的分组的副本。
      分组和确认分组都必须进行编号。
      超时计时器的重传时间应当比数据在分组传输的平均往返时间更长一些。 

      - 确认丢失和确认迟到
      - 信道利用率很低，但是优点是简单

### Rdt2.1：处理出错(garbled)的ACK/NAK

- 发送方处理出错的ACK/NAK

- 接收方处理出错的ACK/NAK

- 讨论

  - 发送方

    - 在分组中加入序列号（seq #）
    - 两个序列号（0，1）就足够了

      - 一次只发送一个未经确认的分组

    - 必须检测ACK/NAK是否出错（需要EDC ）
    - FSM状态数变成了两倍

      - 必须记住当前分组的序列号为0还是1

  - 接收方

    - 必须检测接收到的分组是否是重复的

      - 状态会指示希望接收到的分组的序号为0还是1

    - 注意：接收方并不知道发送方是否正确收到了其ACK/NAK

      - 没有安排确认的确认 

- rdt2.1的运行

  发送方不对收到的ack/nak给确认 
  接收方发送ack，如果后面接收方收到的是： 
  老分组p0？则ack 错误 
  下一个分组？P1，ack正确 

### Rdt2.2: a NAK-free protocol无NAK的协议

- 功能同rdt2.1，但只使用ACK(ack 要编号）
- 接收方对最后正确接收的分组发ACK，以替代NAK

  - 接收方必须显式地(explicitly)包含被正确接收分组的序号

- 当收到重复的ACK（如：再次收到ack0）时，发送方与收到NAK采取相同的动作：重传当前分组
- 为后面的一次发送多个数据单位做一个准备

  - 一次能够发送多个
  - 每一个的应答都有：ACK，NACK；麻烦
  - 使用对前一个数据单位的ACK，代替本数据单位的nak
  - 确认信息减少一半，协议处理简单

- 发送方和接收方片断
- rdt2.2的运行

### Rdt3.0: channels with errors and loss具有比特差错和分组丢失的信道

- 新的假设

  - 下层信道可能会丢失分组（数据或ACK）

- 解决的问题：

  - 会死锁

  - 机制还不够处理这种状况

    检验和（checksum）
    序列号 （seq. #）
    ACK 
    重传 （会有所帮助，但是还不够）

- 方法：

  - 发送方等待ACK一段合理的时间

    此处合理的时间：链路层的timeout时间是确定的。传输层timeout时间是适应式的。

    - 发送端超时重传：如果到时没有收到ACK-》重传
    - 新的问题：如果分组（ACK）只是被延迟了？

      - 重传会导致数据重复，但利用序列号已经可以处理这个问题
      - 接收方必须指明被正确接受的序号

  - 解决新的问题：需要一个倒计数定时器(countdown timer)

    - 在给定的时间量过期后，可中断发送方

- rdt3.0发送方

  - 每次发送一个分组（包括第一次分组和重传分组）时，便启动一个定时器。
  - 响应定时器中断（采取适当的动作）
  - 中止定时器

- rdt3.0的运行

  - rdt3.0可以工作，但链路容量比较大的情况下，性能很差(performance stinks性能不好)

- rdt3.0的性能

  - 瓶颈在于：网络协议限制了物理资源的利用

$$
U_{sender}:利用率 ({\color{red} utilization})-忙于发送的时间比例(fraction of time sender busy sending)
$$

	- 

$$
T_{transmit}=\cfrac{L(分组长度packet length，比特)}{R(传输速度transmission rate，bps)}
$$

	- U为利用率

$$
U_{sender} = \cfrac{L/R}{RTT+L/R}
$$

- rdt3.0: stop-and-wait operation停-等操作
- 流水线协议Pipelined protocols：提高链路利用率

  - 允许发送方在未得到对方确认的情况下一次发送多个分组
  - 必须增加序号的范围:用多个bit表示分组的序号
  - 在发送方/接收方要有缓冲区

    - 发送方缓冲：未得到确认，可能需要重传；
    - 接收方缓存：上层用户取用数据的速率≠接收到的数据速率；接收到的数据可能乱序，排序交付（可靠）

  - 两种通用的流水线协议：

    - 回退N步(go-Back-N，GBN)
    - 选择重传(selective repeat，SR)

### 流水线协议Pipelined protocols：

发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。
由于信道上一直有数据不间断地传送，这种传输方式可获得很高的信道利用率

- Go-back-N和Selective Repeat对比（回退N步和选择重传对比）

  - 发送端发送数量（此点相同）
    一次都可以发送多个未经确认的分组

    - 发送端最多在流水线中有N个
      未确认的分组（unacked packets）
    - 发送端最多在流水线中
      有N个未确认的分组

  - ack对比

    - 接收方对每个到来的分组单独确认individual ack（非累计确认）
    - 接收端只是发送累计型确认cumulative ack
      （接收端如果发现gap，不确认新到来的分组）

  - 定时器对比

    - 发送方为每个未确认的分组保持一个定时器（当超时定时器到时，只是重发到时的未确认分组）
    - 发送端拥有对最早发送的的未确认分组的定时器（只需设置一个定时器，当定时器到时时，重传所有未确认分组）

  - 优点

    - 简单，所需资源少
      （接收方一个缓存单元）
    - 出错时，重传一个
      代价小

  - 缺点

    - 一旦出错，回退N步代价大 
    - 复杂，所需要资源多
      （接收方多个缓存单元）

  - 适用范围

    - 出错率低：比较适合GBN，出错非常罕见，没有必要用复杂的SR，为罕见的事件做日常的准备和复杂处理
    - 链路容量大（延迟大、带宽大）：比较适合SR而不是GBN，一点出错代价太大

  - 窗口的最大尺寸

    - SR:2^(n-1)
    - GBN: 2^n-1

- (Go-back-N,GBN)回退N步，也称为滑动窗口协议

  - 发送端

    - 分组标头中的k位序号
    - “window”最多 N （窗口长度）个，允许连续未确定的分组

  - 发送方扩展的FSM
  - 接收方扩展的FSM

    - 只发送ACK：对顺序接收的最高序号的分组

      - 可能会产生重复的ACK 
      - 只需记住（expectedseqnum）；接收窗口=1(只一个变量就可表示接收窗口)

    - 对乱序的分组：

      - 丢弃（不缓存） →在接收方不被缓存❗
      - 对顺序接收的最高序号的分组进行确认-累计确认

  - 运行中的GBN

- (SR,Selective Repeat)选择重传

  - 接收方对每个正确接收的分组，分别发送
    ACKn（非累积确认）

    - 接收窗口>1（可以缓存乱序的分组，根据需要缓存分组）
    - 最终将分组按顺序交付给上层

  - 发送方只对那些没有收到ACK的分组进行重发-选择性重发

    - 发送方为每个未确认的分组设定一个定时器

  - 发送窗口的最大值（发送缓冲区）限制发送未确认分组的个数
  - 发送方

    - 从上层接收数据

      - 如果下一个可用于该分组的序号可在发送窗口中，则发送

    - timeout(n):

      - 重新发送分组n，重新设定定时器

    - 

$$
ACK_{in [sendbase,sendbase+N]}:
$$

			- 将分组n标记为已接收
			- 如n为最小未确认的分组序号，将base移到下一个未确认序号
	
	- 接收方
	
		- 

$$
分组n_{[rcvbase, rcvbase+N-1]}
$$

			- 发送ACK(n)
			- 乱序：缓存
			- 有序：该分组及以前缓存的序号连续的分组交付给上层，然后将窗口移到下一个仍未被接收的分组
	
		- 

$$
分组n_{[rcvbase-N, rcvbase-1]}
$$

			- ACK(n)
	
		- 其它：
	
			- 忽略该分组
	
	- 接收方，发送方和接受windows示意图
	- 选择重传SR的运行（in action）
	
		- 两难情况（dilemma）
	
			- 接收器在两种情况下没有区别！
			- （b） 中接受为新数据的重复数据
			- 问：seq # 大小和窗口大小之间有什么关系，以避免 （b） 中出现问题？

### 可靠通信的实现

使用上述的确认和重传机制，我们就可以在不可靠的传输网络上实现可靠的通信。
这种可靠传输协议常称为自动重传请求ARQ (Automatic Repeat reQuest)。
ARQ 表明重传的请求是自动进行的。接收方不需要请求发送方重传某个出错的分组 。

- 连续 ARQ 协议 

  - Go-back-N协议表明当通信线路质量不好时，连续 ARQ 协议会带来负面的影响。 

- 累计确认

  接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认，而是对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。
  累积确认有的优点是：容易实现，即使确认丢失也不必重传。缺点是：不能向发送方反映出接收方已经正确收到的所有分组的信息。

- TCP可靠通信的具体实现

  TCP 连接的每一端都必须设有两个窗口——一个发送窗口和一个接收窗口。
  TCP 的可靠传输机制用字节的序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段。
  TCP 两端的四个窗口经常处于动态变化之中。
  TCP连接的往返时间 RTT 也不是固定不变的。需要使用特定的算法估算较为合理的重传时间。  

## 4.5 connection-oriented transport: TCP

点对点：  一个发送方，一个接收方
可靠的、按顺序的字节流：  没有报文边界（no "message boundaries"）
管道化（流水线pipelined）：TCP拥塞控制和流量控制设置，窗口大小
发送和接收缓存send & receive buffers
全双工数据full duplex data： 
在同一连接中数据流双向流动
MSS： maximum segment size最大报文段大小
面向连接：在数据交换之前，通过握手（交换控制报文） 初始化发送方、接收方的状态变量
有流量控制：发送方不会淹没（overwhelm）接收方 

### 4.5.1报文段结构segment structure

- 

  源端口和目的端口字段——各占 2 字节。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。 
  序号字段——占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。 
  确认号字段——占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。 
  数据偏移（即首部长度）——占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。“数据偏移”的单位是 32 位字（以 4 字节为计算单位）。  
  保留字段——占 6 位，保留为今后使用，但目前应置为 0。 
  紧急 URG —— 当 URG = 1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。
   确认 ACK —— 只有当 ACK = 1 时确认号字段才有效。当 ACK = 0 时，确认号无效。 
  推送 PSH (PuSH) —— 接收 TCP 收到 PSH = 1 的报文段，就尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。  
  复位 RST (ReSeT) —— 当 RST = 1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。 
  同步 SYN —— 同步 SYN = 1 表示这是一个连接请求或连接接受报文。 
  终止 FIN (FINis) —— 用来释放一个连接。FIN = 1 表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。
  窗口字段 —— 占 2 字节，用来让对方设置发送窗口的依据，单位为字节。 
  检验和 —— 占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。
  紧急指针字段 —— 占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。  
  选项字段 —— 长度可变。TCP 最初只规定了一种选项，即最大报文段长度 MSS。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节。” 
  MSS (Maximum Segment Size)是 TCP 报文段中的数据字段的最大长度。数据字段加上 TCP 首部才等于整个的 TCP 报文段。
  窗口扩大选项 ——占 3 字节，其中有一个字节表示移位值 S。新的窗口值等于TCP 首部中的窗口位数增大到(16 + S)，相当于把窗口值向左移动 S 位后获得实际的窗口大小。
  时间戳选项——占10 字节，其中最主要的字段时间戳值字段（4 字节）和时间戳回送回答字段（4 字节）。
  选择确认选项——在后面介绍。 
  填充字段 —— 这是为了使整个首部长度是 4 字节的整数倍。 

- TCP seq. numbers, ACKs序号、确认号

  - 序号sequence numbers：

    - 报文段首字节的在字节流的编号

  - 确认号acknowledgements:

    - 期望从另一方收到的下一个字节的序号（seq # ）
    - 累积（cumulative）确认

  - TCP不考虑接收方对乱序的报文段的排序问题
  - 

- TCP round trip time(往返延时, RTT), timeout(超时)

  - 怎样设置TCP超时的值？

    - 比RTT要长， 但RTT是变化的
    - 太短：太早(premature)超时→不必要的重传
    - 太长：对报文段丢失反应太慢

  - 怎样估计(estimate)RTT？

    - SampleRTT：测量从报文段发出到收到ack确认的时间（如果有重传，忽略此次测量）
    - SampleRTT会变化，因此估计的RTT应该比较平滑 → 对几个最近的测量值求平均，而不是仅用当前的SampleRTT

  - EstimatedRTT：加权平均往返时间
    指数加权(exponential weighted)移动平均
    过去样本的影响呈指数衰减
    推荐值：α = 0.125（0<α<1）

$$
EstimatedRTT = (1- \alpha)*EstimatedRTT + \alpha*SampleRTT
$$

		- TCP 保留了 RTT 的一个加权平均往返时间 RTTS（这又称为平滑的往返时间）。

第一次测量到 RTT 样本时，RTTS 值就取为所测量到的 RTT 样本值。以后每测量到一个新的 RTT 样本，就按下式重新计算一次 RTTS：

$$
新的 RTT_S = (1 - \alpha) * (旧的 RTT_S)                        + (\alpha * 新的 RTT 样本)
$$

			- 若 α  很接近于零，表示 RTT 值更新较慢。若选择 α  接近于 1，则表示 RTT 值更新较快。
			- RFC 2988 推荐的 α  值为 1/8，即 0.125。 
	
	- 设置超时时间
	
		- timeout interval超时间隔：EstimtedRTT + 安全边界(safety margin)时间：EstimatedRTT变化大 (方差大)→较大的安全边界时间
	
			- 往返时延的方差很大：由于 TCP 的下层是一个互联网环境，IP 数据报所选择的路由变化很大。因而运输层的往返时间的方差也很大。
	
		- SampleRTT会偏离EstimatedRTT多远：(推荐值：β = 0.25)

$$
DevRTT = (1-\beta)*DevRTT + \beta*|SampleRTT-EstimatedRTT|
$$

		  超时重传时间 RTO (RetransmissionTime-Out) 
		  RTO 应略大于上面得出的加权平均往返时间 RTTS。
		  RFC 2988 建议使用下式计算 RTO：
		   RTO = RTTS + 4 * RTTD                  
		  RTTD 是 RTT 的偏差的加权平均值。
		  RFC 2988 建议这样计算 RTTD。第一次测量时，RTTD 值取为测量到的 RTT 样本值的一半。在以后的测量中，则使用下式计算加权平均的RTTD：
		  新的RTTD = (1 - β) * (旧的RTTD)  + β*RTTS|新的RTT样本| 
		  β是个小于 1 的系数，其推荐值是 1/4，即 0.25。
		  
		- 
		- 超时重传时间的选择：TCP 每发送一个报文段，就对这个报文段设置一次计时器。只要计时器设置的重传时间到但还没有收到确认，就要重传这一报文段。
	
	- 往返时间的测量相当复杂 
	
	  TCP 报文段 1 没有收到确认。重传（即报文段 2）后，收到了确认报文段 ACK。 
	  如何判定此确认报文段是对原来的报文段 1 的确认，还是对重传的报文段 2 的确认？ 
	  
		- Karn 算法
	
			- 在计算平均往返时间 RTT 时，只要报文段重传了，就不采用其往返时间样本。
			- 这样得出的加权平均平均往返时间 RTTS 和超时重传时间 RTO 就较准确。 
	
		- 修正的 Karn 算法 
	
		  报文段每重传一次，就把 RTO 增大一些： 
		  新的 RTO = γ *  (旧的 RTO) 
		  系数 γ的典型值是 2 。 
		  当不再发生报文段的重传时，才根据报文段的往返时延更新平均往返时延 RTT 和超时重传时间 RTO 的数值。 
		  实践证明，这种策略较为合理。 


​		  

	- 选择确认 SACK(Selective ACK) 
	
	  接收方收到了和前面的字节流不连续的两个字节块。 
	  如果这些字节的序号都在接收窗口之内，那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些已收到的数据。 


​	  

		- RCF2018的规定
	
		  如果要使用选择确认，那么在建立 TCP 连接时，就要在 TCP 首部的选项中加上“允许 SACK”的选项，而双方必须都事先商定好。 
		  如果使用选择确认，那么原来首部中的“确认号字段”的用法仍然不变。只是以后在 TCP 报文段的首部中都增加了 SACK 选项，以便报告收到的不连续的字节块的边界。 
		  由于首部选项的长度最多只有 40 字节，而指明一个边界就要用掉 4 字节，因此在选项中最多只能指明 4 个字节块的边界信息。 


​		  

		- 

- TCP可靠传输的实现：以字节为单位的滑动窗口

  - 

    - 

      - 

  - 发送缓存
  - 接收缓存
  - 注意：

    - A 的发送窗口并不总是和 B 的接收窗口一样大（因为有一定的时间滞后）。
    - TCP 标准没有规定对不按序到达的数据应如何处理。通常是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。
    - TCP 要求接收方必须有累积确认的功能，这样可以减小传输开销。  

### 4.5.2 TCP：reliable data transfer可靠数据传输

- 概述

  - TCP在IP不可靠服务的基础上建立了rdt 

    - 管道化的报文段(GBN or SR)
    - 累积确认（像GBN）
    - 单个重传定时器（像GBN）

  - 通过以下事件触发重传

    - 超时（只重发那个最早的未确认段：SR）
    - 重复的确认 

  - 首先考虑简化的TCP发送方：

    - 忽略重复的确认
    - 忽略流量控制和拥塞控制

- TCP sender events发送方事件：

  - 从应用层接收数据：

    - 用nextseq创建报文段
    - 序号nextseq为报文段首字节的字节流编号
    - 如果还没有运行，启动定时器

      - 定时器与最早未确认的报文段关联
      - 过期间隔(expiration interval)：TimeOutInterval

  - 超时：

    - 重传导致超时的报文段
    - 重新启动定时器

  - 收到确认：

    - 如果是对尚未确认的报文段确认

      - 更新已被确认的报文序号
      - 如果当前还有未被确认的报文段，重新启动定时器

  - 简化的状态图

    - TCP重传场景

  - 

- TCP fast retransmit快速重传

  - 超时周期往往太长：在重传丢失报文段之前的
    延时太长
  - 通过重复的ACK来检测报文段丢失

    - 发送方通常连续发送大量报文段
    - 如果报文段丢失，通常会引起多个重复的ACK
    - 原因：如果发送方收到同一数据的3个冗余ACK，重传最小序号的段： 

      - 快速重传：在定时器过时之前重发报文段
        它假设跟在被确认的数据后面的数据丢失了
        第一个ACK是正常的；
        收到第二个该段的ACK，表示接收方收到一个该段后的乱序段；
        收到第3，4个该段的ack，表示接收方收到该段之后的2个，3个乱序段，可能性非常大，段丢失了，无需再等到时延后再重传

### 4.5.3 TCP flow control流量控制

- 接收方控制发送方，不让发送方发的太多太快以至于让接收方的缓冲区溢出

  - 缓冲区TCP往里面写，app从当中读取

- 实现原理：接收方在其向发送方的TCP段头部的rwnd字段“通告”其空闲buffer大小
  发送端将未确认的数据限制为RcvWindow
  Rcvr（接收端）在大于RcvWindow的段找可用空间？？？

  - 虽然达到流量控制，但是应用进程从缓冲区读取时可能会很慢
  - 速度匹配服务：将发送速率与接收应用的消耗速率相匹配
  - 假设TCP接收端丢弃无序报文段时
    缓存中可用的空间=RcvWindow
    = RcvBuffer-[LastByteRcvd - LastByteRead]

- 利用滑动窗口实现流量控制

  一般说来，我们总是希望数据传输得更快一些。但如果发送方把数据发送得过快，接收方就可能来不及接收，这就会造成数据的丢失。 
  流量控制(flow control)就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。 
  利用滑动窗口机制可以很方便地在 TCP 连接上实现流量控制。 


  - 流量控制举例

- 持续计时器(persistence timer)

  TCP 为每一个连接设有一个持续计时器。 
  只要 TCP 连接的一方收到对方的零窗口通知，就启动持续计时器。 
  若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带 1 字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。 
  若窗口仍然是零，则收到这个报文段的一方就重新设置持续计时器。 
  若窗口不是零，则死锁的僵局就可以打破了。 

- 必须考虑传输效率

  可以用不同的机制来控制 TCP 报文段的发送时机: 
  第一种机制是 TCP 维持一个变量，它等于最大报文段长度 MSS。只要缓存中存放的数据达到 MSS 字节时，就组装成一个 TCP 报文段发送出去。 
  第二种机制是由发送方的应用进程指明要求发送报文段，即 TCP 支持的推送(push)操作。 
  第三种机制是发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段（但长度不能超过 MSS）发送出去。 

  

### 4.5.4 connection management连接管理

- Recall：TCP发送方、接收方在交换数据段前建立“连接”

  - 初始化TCP变量

    - 序号seq.#s
    - 缓冲区、流量控制信息（eg.Rcvwindow）

  - 客户端：连接启动器（connection initiator）

    - Socket clientSocket = new Socket("hostname","port number"); 

  - 服务器：由客户联系

    - Socket connectionSocket = welcomeSocket.accept();

- 3次握手

  - 步骤 1：客户端主机将 TCP SYN 段发送到服务器

    - 指定初始序号seq#
    - 无数据

  - 步骤2：服务器主机接收SYN，使用SYNACK段回复

    - 服务器分配缓冲区
    - 指定服务器初始 seq.#

  - 步骤3：客户端接收SYNACK，使用ACK段回复，其中可能包含数据

- 在正式交换数据之前，发送方和接收方握手建立通信关系:

  - 同意建立连接（每一方都知道对方愿意建立连接）
  - 同意连接参数 

- Agreeing to establish a connection同意建立连接

  - 两次握手不总是可以确保建立连接

    - 变化的延迟（连接请求的段没有丢，但可能超时）
    - 由于丢失造成的重传 (e.g.req_conn(x))
    - 报文乱序
    - 相互看不到对方
    - 一个栗子

  - 3次握手

    - 解决的问题：半连接和接收老数据问题
    - 3次握手：FSM

- TCP: 关闭连接closing a connection

  - 客户端，服务器分别关闭它自己这一侧的连接

    - 发送FIN bit = 1的TCP段

  - 一旦接收到FIN，用ACK回应

    - 接到FIN段，ACK可以和它自己发出的FIN段一起发送

  - 可以处理同时(simultaneous)的FIN交换 

### 总结：

- 1.  运输连接的三个阶段 

  运输连接就有三个阶段，即：连接建立、数据传送和连接释放。运输连接的管理就是使运输连接的建立和释放都能正常地进行。 
  连接建立过程中要解决以下三个问题： 
  要使每一方能够确知对方的存在。 
  要允许双方协商一些参数（如最大报文段长度，最大窗口大小，服务质量等）。 
  能够对运输实体资源（如缓存大小，连接表中的项目等）进行分配。 

- 客户服务器方式

  TCP 连接的建立都是采用客户服务器方式。 
  主动发起连接建立的应用进程叫做客户(client)。 
  被动等待连接建立的应用进程叫做服务器(server)。 

- 过程：握手、连接释放PPT p164-177

  - A 必须等待 2MSL 的时间

    第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B。 
    第二，防止 “已失效的连接请求报文段”出现在本连接中。A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段，都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。 

## 4.6 principles of congestion control拥塞控制原理

### 拥塞:

- 非正式的定义: “太多的数据需要网络传输，超过了网络的处理能力”
- 与流量控制不同
- 拥塞的表现manifestations:

  - 分组丢失 (路由器缓冲区溢出)
  - 分组经历比较长的延迟(在路由器的队列中排队)

- 拥塞的原因/代价: 场景(scenario)1
- 拥塞的原因/代价: 场景2

  - 

    - 

  - 

    - retrans（重传）

- 拥塞的原因/代价: 场景3

  - 

### 拥塞控制方法

- 端到端拥塞控制:

  - 没有来自网络的显式反馈
  - 端系统根据延迟和丢失事件推断是否有拥塞
  - TCP采用的方法

- 网络辅助的拥塞控制:

  - 路由器提供给端系统以反馈信息
  - 单个bit置位，显示有拥塞 (SNA, DECbit,TCP/IP ECN, ATM)
  - 显式提供发送端可以采用的速率

## 4.7 TCP congestion control（TCP拥塞控制）

### TCP 拥塞控制：AIMD（additive increase multiplication decrease）加性增，乘性减

- 方法：发送方提高传输速率（窗口大小），探测可用带宽，直到发生丢失

  如何控制发送端发送的速率
  维持一个拥塞窗口的值：CongWin（cwnd）
  发送端限制已发送但是未确认的数据量（的上限）: LastByteSent-LastByteAcked ≤ CongWin
  从而粗略地控制发送方的往网络中注入的速率

  - 加法增加：
    当CongWin>阈值时，一个RTT如没有发生丢失事件 ,将CongWin加1MSS: 探测
  - 乘法减少:
    丢失事件后将CongWin降为1，将CongWin/2作为阈值，进入慢启动阶段（倍增直到CongWin/2）
  - cwnd是动态的，有感知网络拥塞的功能
  - TCP发送速率：
    大致就是cwnd字节，等待RTT的ACKS，然后发送更多字节

### TCP慢启动

- 当连接开始时，指数性增加（每个RTT）发送速率直到发生丢失事件

  - 连接刚建立, CongWin = 1MSS
  - 每一个RTT， CongWin加倍
  - 每收到一个ACK时，CongWin加1（why）
  - 慢启动阶段：只要不超时或3个重复ack，一个RTT， CongWin加倍

- 总结: 初始速率很慢，但是加速却是指数性的

  - 指数增加，SS时间很短，长期来看可以忽略

### TCP：detecting, reacting to loss

检测、对丢失的反应

- loss indicated by timeout
  超时指示的损失：

  - 1.cwnd 设置为 1 MSS;
  - 2.然后窗口呈指数级增长（exponentially）（如在慢启动时）到阈值（threshold），然后线性（linearly）增长

- 由 3 个重复的 ACK 指示的丢失：TCP RENO

  - dup ACK 表示网络能够提供某些网段
  - cwnd被切成两半的窗口，然后线性增长

- TCP Tahoe 始终将 cwnd 设置为 1（超时timeout或 3 个重复的 ack）

### TCP：从慢启动切换到 CA（switching from slow start to CA）

- 问：指数增长何时应切换到线性？
  答：当cwnd在超时之前达到其值的1/2时。
- 实现：通过可变的ssthresh
  在loss事件时，ssthresh 设置为亏损事件发生前 cwnd 的 1/2

### 总结：

### TCP吞吐量throughput

- TCP的平均吞吐量是多少，使用窗口window尺寸W和RTT来描述?
  忽略慢启动阶段，假设发送端总有数据传输
- 

### 

### TCP公平性fairness

- 公平性目标goal：

  - 如果 K个TCP会话分享一个链路带宽为R的瓶颈，每一个会话的有效带宽为 R/K

- TCP公平的原因

  - 

### Explicit Congestion Notification (ECN)

- 网络辅助拥塞控制:

  TOS字段中2个bit被网络路由器标记，用于指示是否发 生拥塞
  拥塞指示被传送到接收主机
  在接收方-到发送方的ACK中，接收方(在IP数据报中看到了拥塞指示）设置ECE bit，指示发送方发生了拥塞 

## 总结：

### 拥塞控制的一般原理 

在某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏——产生拥塞(congestion)。 
出现资源拥塞的条件： 对资源需求的总和 > 可用资源 
若网络中有许多资源同时产生拥塞，网络的性能就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。 

拥塞控制是很难设计的，因为它是一个动态的（而不是静态的）问题。 
当前网络正朝着高速化的方向发展，这很容易出现缓存不够大而造成分组的丢失。但分组的丢失是网络发生拥塞的征兆而不是原因。 
在许多情况下，甚至正是拥塞控制本身成为引起网络性能恶化甚至发生死锁的原因。这点应特别引起重视。 


### 拥塞控制与流量控制的关系 

拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。 
拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。 
流量控制往往指在给定的发送端和接收端之间的点对点通信量的控制。 
流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 


### 开环控制和闭环控制

开环控制方法就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。 
闭环控制是基于反馈环路的概念。属于闭环控制的有以下几种措施： 
监测网络系统以便检测到拥塞在何时、何处发生。 
将拥塞发生的信息传送到可采取行动的地方。 
调整网络系统的运行以解决出现的问题。 

### 几种拥塞控制方法

- 1.  慢开始和拥塞避免

  发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。如再考虑到接收方的接收能力，则发送窗口还可能小于拥塞窗口。 
  发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 


  - 慢开始算法原理

    在主机刚刚开始发送报文段时可先设置拥塞窗口 cwnd = 1，即设置为一个最大报文段 MSS 的数值。 
    在每收到一个对新的报文段的确认后，将拥塞窗口加 1，即增加一个 MSS 的数值。 
    用这样的方法逐步增大发送端的拥塞窗口 cwnd，可以使分组注入到网络的速率更加合理。 

  - 传输轮次(transmission round)

    使用慢开始算法后，每经过一个传输轮次，拥塞窗口 cwnd 就加倍。 
    一个传输轮次所经历的时间其实就是往返时间 RTT。 
    “传输轮次”更加强调：把拥塞窗口 cwnd 所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 
    例如，拥塞窗口 cwnd = 4，这时的往返时间 RTT 就是发送方连续发送 4 个报文段，并收到这 4 个报文段的确认，总共经历的时间。 

  - 设置慢开始门限状态变量ssthresh

    慢开始门限 ssthresh 的用法如下： 
    当 cwnd < ssthresh 时，使用慢开始算法。 
    当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 
    当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。 
    拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。 

  - 当网络出现拥塞时

    无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认），就要把慢开始门限 ssthresh 设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。 
    然后把拥塞窗口 cwnd 重新设置为 1，执行慢开始算法。 
    这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 

  - 慢开始和拥塞避免算法的实现举例 

    当 TCP 连接进行初始化时，将拥塞窗口置为 1。图中的窗口单位不使用字节而使用报文段。 
    慢开始门限的初始值设置为 16 个报文段， 
    即 ssthresh = 16。 
    发送端的发送窗口不能超过拥塞窗口 cwnd 和接收端窗口 rwnd 中的最小值。我们假定接收端窗口足够大，因此现在发送窗口的数值等于拥塞窗口的数值。 
    在执行慢开始算法时，拥塞窗口 cwnd 的初始值为 1，发送第一个报文段 M0。 
    发送端每收到一个确认 ，就把 cwnd 加 1。于是发送端可以接着发送 M1 和 M2 两个报文段。 
    接收端共发回两个确认。发送端每收到一个对新报文段的确认，就把发送端的 cwnd 加 1。现在 cwnd 从 2 增大到 4，并可接着发送后面的 4 个报文段。 
    发送端每收到一个对新报文段的确认，就把发送端的拥塞窗口加 1，因此拥塞窗口 cwnd 随着传输轮次按指数规律增长。
    当拥塞窗口 cwnd 增长到慢开始门限值 ssthresh 时（即当 cwnd = 16 时），就改为执行拥塞避免算法，拥塞窗口按线性规律增长。 
    假定拥塞窗口的数值增长到 24 时，网络出现超时，表明网络拥塞了。 
    更新后的 ssthresh 值变为 12（即发送窗口数值 24 的一半），拥塞窗口再重新设置为 1，并执行慢开始算法。 
    当 cwnd = 12 时改为执行拥塞避免算法，拥塞窗口按按线性规律增长，每经过一个往返时延就增加一个 MSS 的大小。 

  - 乘法减小(multiplicative decrease) 

    “乘法减小“是指不论在慢开始阶段还是拥塞避免阶段，只要出现一次超时（即出现一次网络拥塞），就把慢开始门限值 ssthresh 设置为当前的拥塞窗口值乘以 0.5。 
    当网络频繁出现拥塞时，ssthresh 值就下降得很快，以大大减少注入到网络中的分组数。 

  - 加法增大(additive increase) 

    “加法增大”是指执行拥塞避免算法后，在收到对所有报文段的确认后（即经过一个往返时间），就把拥塞窗口 cwnd增加一个 MSS 大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。 

  - “拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。

“拥塞避免”是说在拥塞避免阶段把拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。 

- 2.  快重传和快恢复

  快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认。这样做可以让发送方及早知道有报文段没有到达接收方。 
  发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段。 
  不难看出，快重传并非取消重传计时器，而是在某些情况下可更早地重传丢失的报文段。 


  - 快重传举例

  - 快恢复算法

    (1) 当发送端收到连续三个重复的确认时，就执行“乘法减小”算法，把慢开始门限 ssthresh 减半。但接下去不执行慢开始算法。 
    (2)由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，即拥塞窗口 cwnd 现在不设置为 1，而是设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。 

  - 发送窗口的上限值

    发送方的发送窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，即应按以下公式确定： 发送窗口的上限值 = Min [rwnd, cwnd] 
    当 rwnd < cwnd 时，是接收方的接收能力限制发送窗口的最大值。 
    当 cwnd < rwnd 时，则是网络的拥塞限制发送窗口的最大值。 

### 随机早期检测 RED (Random Early Detection) 

使路由器的队列维持两个参数，即队列长度最小门限 THmin 和最大门限 THmax。 
RED 对每一个到达的数据报都先计算平均队列长度 LAV。 
若平均队列长度小于最小门限 THmin，则将新到达的数据报放入队列进行排队。 
若平均队列长度超过最大门限 THmax，则将新到达的数据报丢弃。 
若平均队列长度在最小门限 THmin 和最大门限THmax 之间，则按照某一概率 p 将新到达的数据报丢弃。 

- 

  - 




{% endmarkmap %}
